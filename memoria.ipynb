{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEMA**\n",
    "\n",
    "PREDICCIÓN DE PRECIOS EN EL MERCADO INMOBILIARIO DE MADRID.\n",
    "\n",
    "\n",
    "**Suponemos el siguiente problema de negocio:**\n",
    "\n",
    "Una empresa inmobiliaria de Madrid nos pide que hagamos un modelo para poder generar precios de compraventa de inmuebles lo más ajustados a la realidad posibles.\n",
    "  \n",
    "La  empresa considera que esos precios son muy útiles para el negocio, por motivos como los siguientes:  \n",
    "- Para ofrecer rápidamente a un posible venededor una estimación del precio al que podrían poner sus inmuebles en venta. Eso ayuda a captar clientes.\n",
    "- Para orientar a los compradores sobre los precios de inmuebles que reunan características que ellos demandan.\n",
    "- Para la propia empresa, para conocer cómo está el mercado y poder destinar recursos a las operaciones  a priori más rentables.\n",
    "- Pare tener una herramienta que se pueda actualizar con nueva información y así adaptarse a la rápida evolución de este sector.\n",
    "\n",
    "**Obtención de los datos**\n",
    "\n",
    "Para ello se va a usar una base de datos obtenida a traves de KAGGLE. \n",
    "Se trata de una agrupacion de información de portales inmobiliarios de inmuebles situados en MADRID con más de 20.000 registros, lo que debería darle mucha solidez.  \n",
    "\n",
    " Se han obtenido datos de la web https://www.kaggle.com/mirbektoktogaraev/madrid-real-estate-market. Kaggle (propiedad de Google) es una plataforma en línea que  permite a los usuarios encontrar y publicar conjuntos de datos, explorar y crear modelos en un entorno basado en la web. Es una web pública con datos de anfitriones que trabajan con la plataforma.\n",
    "\n",
    "En la base de datos hay muchas variables, tanto descriptivas (con texto) como categóricas, numéricas y booleanas.  \n",
    "Veremos si se pueden eliminar todas las que no tengan datos suficientes o no aporten casi información o esta sea redundante respecto a otra variable.\n",
    "\n",
    "\n",
    "**Objetivos:**\n",
    "\n",
    "- Ver qué factores están condicionando el precio y si alguno tiene relevancia especial.\n",
    "- Obtener el modelo más sencillo, rápido y flexible posible.\n",
    "- Que el modelo sea fácil de mantener, reentrenar y de adaptar a datos de otras ciudades.\n",
    "\n",
    "**La hipótesis de partida:**  \n",
    "\n",
    "Pensamos que:\n",
    "- Hay varibles que por su natureza suelen tener mucha relación con el precio final, como pueden ser los metros cuadrados, número de habitaciones, localización ,etc.\n",
    "\n",
    "Otros supuestos menores menores son:  \n",
    "\n",
    "- Hay otros datos que son más bien burocráticos y que no sabemos qué relación con el precio final tendrán como la calificación energética.\n",
    "- Hay información que solo se porporciona en algunos casos, supongamos que es también útil para nuestro modelo y ya veremos como si tiene jardín, es exterior, tiene calefacción etc.\n",
    "- Hay información contenida en algunas variables que también se puede encontrar en otras variables como identiicadores de localización, barrio, distrito, calle, etc. Posiblemente pueda prescindirse de alguno para que sea más fácil y barato tratar los datos.\n",
    "- Hay variables con información muy relacionada entre sí y con posiblemente el mismo efecto en el precio de venta, como puedan ser los metros cuadrados construídos, el número de habitaciones, etc. Posiblemente se pueda prescindir de alguna también para agilizar el procesado.\n",
    "- Cuantas menos variables necesitemos para predecir más fácil  y barato resultará para la empresa usar y mantener el modelo.\n",
    "\n",
    "**Preparación de funciones auxiliares**\n",
    "\n",
    "Se han programado y puesto en un script una serie de funciones que puden ser llamadas de forma recurrente desde el notebook principal para ver aspectos como la descripción de los datos, las cardinalidades, los *missings*, etc y que evitan tener que escribir mucho código repetitivo.\n",
    "\n",
    "**Herramientas de visualización**\n",
    "\n",
    "Se prepara un scrip con herramientas de visualización que son muy útiles.\n",
    "\n",
    "**Visualización inicial**\n",
    "\n",
    "Nos descagamos las librerias de python que podemos necesitar.\n",
    "Tras la carga de los datos, se muestran en un dataframe y se ve la tipología asignada por Python por defecto.\n",
    "\n",
    "**Separación entre train y test**\n",
    "\n",
    "Inmediatamente, antes de hacer nada, se separan los datos en un 80% para entrenar (train) y un 20% para probar (test).\n",
    "\n",
    "**Análisis exploratorio de datos (EDA)**\n",
    "\n",
    "Definimos como *target* el precio de compra,  como es natural, porque es lo que intentamos predecir.\n",
    "Se hace un visualizado masivo de todas las distribuciones y las correlaciones de todas las variables.\n",
    "\n",
    "Como el  preprocesado lo haremos con *pipelines* se van analizando las variables y han ido creando cuatro listas:\n",
    "\n",
    "- **Variables categóricas**: el tipo de inmueble, el distrito y el certificado energético.\n",
    "- **Variables numércias**: comprende los metros cuadrados, el número  de habitaciones, el número de baños y los precios por metro cuadrado según las zonas.\n",
    "- **Variables booleanas**: algunas aparecían como *object* pero eran boolenas encubiertas.  \n",
    "- **Variables a eliminar**: el resto.\n",
    "\n",
    "\n",
    "\n",
    "**Preprocesado:**\n",
    "\n",
    "Se generan pipelines para las transformaciones de las variables de la siguiente forma:\n",
    "\n",
    "- Variables categóricas: vamos a preparar un pipeline con un one-hot-encoder para desplegar cada categoría de forma individual en cada variable.\n",
    "- Variables numéricas: como hemos visto que las distribuciones son algo irregulares, para facilitar la regresión vamos a aplicar un *StandardScaler* y un logaritmo.\n",
    "- Variables a eliminar: generaremos un pipeline con la orden *drop* para eliminarlos.\n",
    "- Variables booleanas: como ya están tratadas de antemano, no se van a tocar, el pipeline no las transformará.\n",
    "\n",
    "Para ver las columnas que nos van quedando hemos ido creando una lista llamada \"Columns Remaining\" para ver las que nos quedan y observamos que tras aplicar el preprocesado tendríamos 23 columnas, que tras el preprocesado, por efecto del *one-hot-encoder* pasarían a ser 53. \n",
    "Por ahora no las reducimos hasta ver los tiempos de entrenamiento de los modelos.\n",
    "\n",
    "\n",
    "**Elección del modelo**\n",
    "\n",
    "Vamos a seleccinar cuatro modelos de regresión. Los hemos importado de las librerías *scikit-learn* y serán:  \n",
    "- *LinearRegression*: con este modelo haremos una regresión linear multivariante. Este modelo es sencillo y rápido.\n",
    "- *RandomForestRegressor*: también es sencillo y rápido.\n",
    "- *XGBoostRegressor*: capta relaciones no lineales. Es potente para usar con muchos datos y de cierta complejidad. Aquí al haber tratado tanto los datos puede que no sea necesario, pero si en el futuro la base de datos se hace más complicada podría usarse. Además suele prevenenir el sobreajuste. Lo probamos.\n",
    "- *LighGBMRegressor*: captura también relaciones no lineasles, escala muy bien para bases de datos grandes y maneja bien las categóricas. Si no pudiéramos tratar las categóricas nos ayudaría, aunque las hemos tratado. Lo probamos.\n",
    "\n",
    "**Entrenamiento**\n",
    "\n",
    "Creamos el pipeline de preprocesado como hemos indicado anteriormente y se deja para incluirlo en el entrenamiento.\n",
    "\n",
    "Tran instanciar los cuatro modelos con **Pipelines** hacemos un *baseline* con **Cross Validation** para tomar como referencia las siguientes métricas: \n",
    "\n",
    "    - R² (Coeficiente de Determinación): cuanto más alto mejor, más queda explicada la variable dependiente por las independientes.\n",
    "    - MSE(Errorr Cuadrático Medio): cuanto más bajo mejor, los errores serán más pequeños. \n",
    "    - MAE (Error Absoluto Medio): cuanto más bajo mejor, los errores serán más pequeños.\n",
    "    - MEA (Mediana del Error Abosluto): cuanto más bajo mejor, los errores serán más pequeños.\n",
    "\n",
    "**Resultados**\n",
    "\n",
    "Sorprendentemente los cuatro modelos predicen muy bien.\n",
    "El mejor es la ***Regresión lineal*** con un R2 de prácticamente 1. Resulta extraño, los datos podrían haberse contaminado y estar incluyendo el valor a predecir dentro del dataset de entrenamiento. \n",
    "\n",
    "Probamos a eliminar en un notebook aparte las dos variables que más correlación tenían con el target, metros cuadrados y número de baños y el R2 pasa a ser 0.80.  \n",
    "Por ello no nos atrevemos a descartar el modelo y seguiremos adelante con él.\n",
    "Más adelante habría que hacer más pruebas para ver si ha pasado algo con los datos.\n",
    "\n",
    "**Prueba contra el test**\n",
    "\n",
    "Entrenamos de nuevo el *Regresor Lineal*, lo probamos contra el set de prueba (*test_set*) y parece que el R2 ya baja a un 0.8, lo que es una métrica  más normal.\n",
    "Extraremos los coeficientes y los ordenamos por peso de mayor a menor del regresor y ya podemos extraer conclusiones.\n",
    "\n",
    "**Guardado**\n",
    "\n",
    "Guardamos el modelo entrenado con formato .pkl para poderlo usar en comprobaciones posteriores o si fuera el caso dese una API en una web.\n",
    "\n",
    "**CONCLUSIONES**\n",
    "\n",
    "Los precios es la variable a determinar.  \n",
    "No hay sorpresas en los determinantes del precio de venta de un inmueble en Madrid.  \n",
    "Lo más importante es la localización y el tipo de vivienda.  \n",
    "Luego los metros cuadrados y número de estancias/baños juegan también un papel decisivo.  \n",
    "Hasta aquí nada nuevo, lo importante es que nuestro modelo una vez revisado podría determinar con bastante exactitud el precio de venta aproximado de un inmueble tras darle una serie de características.  \n",
    "Y lo haría de forma extremadamente rápida.  \n",
    "Cualquiera de los cuatro modelos manejados dan buenos resultados y todos se pueden adaptar a nuevas bases de datos de otras ciudades o reentrenar con nuevos datos según avance el tiempo y se produzcan más transacciones.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[def]: attachment:image.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
